{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of the crash severity information in CAS data\n",
    "\n",
    "In this notebook, we will explore the severity of crashes, as it will be the\n",
    "target of our predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crash_prediction import cas_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seaborn default style\n",
    "sb.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first, we ensure we have the data or download it if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_path = Path(\"..\") / \"data\" / \"cas_dataset.csv\"\n",
    "if not dset_path.exists():\n",
    "    dset_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cas_data.download(dset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = pd.read_csv(dset_path)\n",
    "dset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CAS dataset has 4 features that can be associated with the crash severity:\n",
    "\n",
    "- `crashSeverity`, severity of a crash, determined by the worst injury\n",
    "   sustained in the crash at time of entry,\n",
    "- `fatalCount`, count of the number of fatal casualties associated with this\n",
    "  crash,\n",
    "- `minorInjuryCount`, count of the number of minor injuries associated with\n",
    "  this crash,\n",
    "- `seriousInjuryCount`, count of the number of serious injuries associated\n",
    "  with this crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_features = [\n",
    "    \"fatalCount\",\n",
    "    \"seriousInjuryCount\",\n",
    "    \"minorInjuryCount\",\n",
    "    \"crashSeverity\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "for ax, feat in zip(axes.flat, severity_features):\n",
    "    counts = dset[feat].value_counts(dropna=False)\n",
    "    counts.plot.bar(ylabel=\"# crashes\", title=feat, ax=ax)\n",
    "    ax.set(yscale=\"log\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the geographical distribution, we will focus on Auckland and replace\n",
    "discrete levels of `crashSeverity` with number to ease plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_auckland = dset[dset[\"X\"].between(174.7, 174.9) & dset[\"Y\"].between(-37, -36.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"Non-Injury Crash\": 1,\n",
    "    \"Minor Crash\": 2,\n",
    "    \"Serious Crash\": 3,\n",
    "    \"Fatal Crash\": 4,\n",
    "}\n",
    "dset_auckland = dset_auckland.replace({\"crashSeverity\": mapping})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the data set imbalance, we plot the local maxima to better see the\n",
    "location of more severe car crashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "for ax, feat in zip(axes.flat, severity_features):\n",
    "    dset_auckland.plot.hexbin(\n",
    "        \"X\",\n",
    "        \"Y\",\n",
    "        feat,\n",
    "        gridsize=500,\n",
    "        reduce_C_function=np.max,\n",
    "        cmap=\"BuPu\",\n",
    "        title=feat,\n",
    "        ax=ax,\n",
    "        sharex=False,\n",
    "    )\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few remarks coming from these plots:\n",
    "\n",
    "- fatal counts are (hopefully) very low,\n",
    "- crashes with serious injuries are also very sparse,\n",
    "- crashes with minor injuries are denser and seem to follow major axes,\n",
    "- the crash severity feature looks like the most homogeneous feature, yet\n",
    "  highlighting some roads more than others.\n",
    "\n",
    "The crash severity is probably a good go-to target, as it's quite\n",
    "interpretable and actionable. The corresponding ML problem is a supervised\n",
    "multi-class prediction problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO document this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset[\"X_bin\"] = pd.cut(dset[\"X\"], 30000)\n",
    "dset[\"Y_bin\"] = pd.cut(dset[\"Y\"], 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = (\n",
    "    dset.groupby([\"X_bin\", \"Y_bin\"], observed=True)\n",
    "    .size()\n",
    "    .reset_index(name=\"crashesCounts\")\n",
    ")\n",
    "severe_counts = (\n",
    "    dset.groupby([\"X_bin\", \"Y_bin\"], observed=True)\n",
    "    .apply(lambda x: (x[\"crashSeverity\"] != \"Non-Injury Crash\").sum())\n",
    "    .reset_index(name=\"severeCounts\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = counts.merge(severe_counts)\n",
    "counts[\"severeRatio\"] = counts[\"severeCounts\"] / counts[\"crashesCounts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = counts.loc[counts[\"crashesCounts\"] > 300, \"severeRatio\"].median()\n",
    "xs = np.linspace(counts[\"crashesCounts\"].min(), counts[\"crashesCounts\"].max(), 100)\n",
    "counts_rvs = st.binom(xs, ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = st.binom(xs, ratio).ppf(0.025) / xs\n",
    "upper_bound = st.binom(xs, ratio).ppf(0.975) / xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = counts.plot.scatter(\n",
    "    x=\"crashesCounts\", y=\"severeRatio\", alpha=0.3, c=\"b\", s=2, figsize=(10, 7)\n",
    ")\n",
    "ax.plot(xs, lower_bound, \"-k\")\n",
    "ax.plot(xs, upper_bound, \"-k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Original computing environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date -R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uname -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
